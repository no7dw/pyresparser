{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('./j_detail.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import jieba\n",
    "                \n",
    "ps = nltk.PorterStemmer()\n",
    "stopwords =[]\n",
    "with open(\"./stopwords.txt\") as file:  \n",
    "    stopwords = file.read() \n",
    "\n",
    "# stopwords =nltk.corpus.stopwords.words('english')\n",
    "all_stop_words = stopwords.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java开发工程师\n"
     ]
    }
   ],
   "source": [
    "job_titles = df.groupby('positionName').size().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "#todo match and merge job_title type by a known dict or ETL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skillset():\n",
    "    def find(self, df_tmp):    \n",
    "        def clean_text(text):\n",
    "            text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "            tokens = re.split('\\W+', text)\n",
    "            text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "            return text\n",
    "\n",
    "        def jiebaclearText(text, all_stop_words=''):\n",
    "\n",
    "            mywordlist = ''\n",
    "            seg_list = jieba.cut(text, cut_all=False, HMM=True)\n",
    "            f_stop_seg_list=all_stop_words\n",
    "            for myword in seg_list:\n",
    "                if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:\n",
    "                    mywordlist = mywordlist + ' ' + myword.lower()\n",
    "            return mywordlist\n",
    "        \n",
    "        df_tmp['clean'] = df_tmp['jd'].apply(lambda x: jiebaclearText(x))\n",
    "\n",
    "        words = ''\n",
    "        for w in df_tmp['clean']:\n",
    "            words = words + ' '+ w\n",
    "        words = words.split()\n",
    "        #in fact need a set\n",
    "\n",
    "        from nltk.probability import FreqDist\n",
    "        fdist = FreqDist(words)\n",
    "        tops=fdist.most_common(1000)\n",
    "\n",
    "        import re\n",
    "        m_list = []\n",
    "        for re_str in tops:\n",
    "        #     m = re.findall('[\\u4e00-\\u9fa5]', re_str[0].strip().lower())\n",
    "            m = re.findall('^[a-zA-Z].*', re_str[0].strip().lower())\n",
    "            if len(m)>=1:\n",
    "                m_list.append(m[0])\n",
    "\n",
    "        df_out=pd.DataFrame({\"java\":m_list  })\n",
    "        df_out.to_csv('skillset/'+job_title+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c++开发工程师\n",
      "推荐算法工程师\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "软件测试工程师\n",
      "前端工程师\n",
      "高级前端开发工程师\n",
      "高级测试工程师\n",
      "web前端工程师\n",
      "web前端\n",
      "数据挖掘工程师\n",
      "测试开发工程师\n"
     ]
    }
   ],
   "source": [
    "df['positionName']=df['positionName'].apply(lambda x: str(x).lower())\n",
    "job_titles = df.groupby('positionName').size().sort_values(ascending=False) \n",
    "for job_title in job_titles.keys()[10:20]:\n",
    "    print(job_title)\n",
    "    try:\n",
    "        df_tmp = df[df['positionName'].str.contains(job_title)]\n",
    "        s = Skillset()\n",
    "        s.find(df_tmp)\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "\n",
    "# tops\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
